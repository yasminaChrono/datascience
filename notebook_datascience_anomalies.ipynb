{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22a16d21-97c6-4ca6-adef-98c60eb93c02",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Import des packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2d7c2a1-1c11-43db-95d3-aeeda6e8d4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: snowflake-connector-python==3.0.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (3.0.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from snowflake-connector-python==3.0.0) (2.1.0)\n",
      "Requirement already satisfied: pyOpenSSL<24.0.0,>=16.2.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from snowflake-connector-python==3.0.0) (22.0.0)\n",
      "Requirement already satisfied: pytz in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from snowflake-connector-python==3.0.0) (2019.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from snowflake-connector-python==3.0.0) (2022.6.15)\n",
      "Requirement already satisfied: setuptools>34.0.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from snowflake-connector-python==3.0.0) (49.6.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from snowflake-connector-python==3.0.0) (4.3.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from snowflake-connector-python==3.0.0) (1.26.9)\n",
      "Requirement already satisfied: pycryptodomex!=3.5.0,<4.0.0,>=3.2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from snowflake-connector-python==3.0.0) (3.15.0)\n",
      "Requirement already satisfied: cffi<2.0.0,>=1.9 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from snowflake-connector-python==3.0.0) (1.15.1)\n",
      "Requirement already satisfied: pyjwt<3.0.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from snowflake-connector-python==3.0.0) (2.4.0)\n",
      "Requirement already satisfied: cryptography<41.0.0,>=3.1.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from snowflake-connector-python==3.0.0) (36.0.2)\n",
      "Requirement already satisfied: filelock<4,>=3.5 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from snowflake-connector-python==3.0.0) (3.7.1)\n",
      "Requirement already satisfied: asn1crypto<2.0.0,>0.24.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from snowflake-connector-python==3.0.0) (1.5.1)\n",
      "Requirement already satisfied: oscrypto<2.0.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from snowflake-connector-python==3.0.0) (1.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from snowflake-connector-python==3.0.0) (3.3)\n",
      "Requirement already satisfied: requests<3.0.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from snowflake-connector-python==3.0.0) (2.28.1)\n",
      "Requirement already satisfied: pycparser in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from cffi<2.0.0,>=1.9->snowflake-connector-python==3.0.0) (2.21)\n",
      "Collecting pyarrow==8.0.0\n",
      "  Using cached pyarrow-8.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.4 MB)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from pyarrow==8.0.0) (1.21.6)\n",
      "\u001b[31mERROR: azureml-dataset-runtime 1.44.0 has requirement pyarrow<6.0.1,>=0.17.0, but you'll have pyarrow 8.0.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: pyarrow\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 10.0.1\n",
      "    Uninstalling pyarrow-10.0.1:\n",
      "      Successfully uninstalled pyarrow-10.0.1\n",
      "Successfully installed pyarrow-8.0.0\n",
      "Requirement already satisfied: azure-keyvault-secrets in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (4.6.0)\n",
      "Requirement already satisfied: six>=1.11.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-keyvault-secrets) (1.16.0)\n",
      "Requirement already satisfied: azure-core<2.0.0,>=1.20.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-keyvault-secrets) (1.24.2)\n",
      "Requirement already satisfied: msrest>=0.6.21 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-keyvault-secrets) (0.7.1)\n",
      "Requirement already satisfied: azure-common~=1.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-keyvault-secrets) (1.1.28)\n",
      "Requirement already satisfied: typing-extensions>=4.0.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-core<2.0.0,>=1.20.0->azure-keyvault-secrets) (4.3.0)\n",
      "Requirement already satisfied: requests>=2.18.4 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-core<2.0.0,>=1.20.0->azure-keyvault-secrets) (2.28.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from msrest>=0.6.21->azure-keyvault-secrets) (2022.6.15)\n",
      "Requirement already satisfied: requests-oauthlib>=0.5.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from msrest>=0.6.21->azure-keyvault-secrets) (1.3.1)\n",
      "Requirement already satisfied: isodate>=0.6.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from msrest>=0.6.21->azure-keyvault-secrets) (0.6.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.20.0->azure-keyvault-secrets) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.20.0->azure-keyvault-secrets) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.20.0->azure-keyvault-secrets) (2.1.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.21->azure-keyvault-secrets) (3.2.0)\n",
      "Requirement already satisfied: pandas in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (1.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from pandas) (2019.3)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from pandas) (1.21.6)\n",
      "Requirement already satisfied: six>=1.5 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "Requirement already satisfied: snowflake-connector-python[pandas] in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (3.0.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from snowflake-connector-python[pandas]) (4.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from snowflake-connector-python[pandas]) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from snowflake-connector-python[pandas]) (1.26.9)\n",
      "Requirement already satisfied: asn1crypto<2.0.0,>0.24.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from snowflake-connector-python[pandas]) (1.5.1)\n",
      "Requirement already satisfied: setuptools>34.0.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from snowflake-connector-python[pandas]) (49.6.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from snowflake-connector-python[pandas]) (3.3)\n",
      "Requirement already satisfied: pyjwt<3.0.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from snowflake-connector-python[pandas]) (2.4.0)\n",
      "Requirement already satisfied: oscrypto<2.0.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from snowflake-connector-python[pandas]) (1.3.0)\n",
      "Requirement already satisfied: requests<3.0.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from snowflake-connector-python[pandas]) (2.28.1)\n",
      "Requirement already satisfied: pytz in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from snowflake-connector-python[pandas]) (2019.3)\n",
      "Requirement already satisfied: filelock<4,>=3.5 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from snowflake-connector-python[pandas]) (3.7.1)\n",
      "Requirement already satisfied: cryptography<41.0.0,>=3.1.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from snowflake-connector-python[pandas]) (36.0.2)\n",
      "Requirement already satisfied: pycryptodomex!=3.5.0,<4.0.0,>=3.2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from snowflake-connector-python[pandas]) (3.15.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from snowflake-connector-python[pandas]) (2.1.0)\n",
      "Requirement already satisfied: pyOpenSSL<24.0.0,>=16.2.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from snowflake-connector-python[pandas]) (22.0.0)\n",
      "Requirement already satisfied: cffi<2.0.0,>=1.9 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from snowflake-connector-python[pandas]) (1.15.1)\n",
      "Requirement already satisfied: pandas<1.6.0,>=1.0.0; extra == \"pandas\" in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from snowflake-connector-python[pandas]) (1.1.5)\n",
      "Collecting pyarrow<10.1.0,>=10.0.1; extra == \"pandas\"\n",
      "  Using cached pyarrow-10.0.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.0 MB)\n",
      "Requirement already satisfied: pycparser in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from cffi<2.0.0,>=1.9->snowflake-connector-python[pandas]) (2.21)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from pandas<1.6.0,>=1.0.0; extra == \"pandas\"->snowflake-connector-python[pandas]) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from pandas<1.6.0,>=1.0.0; extra == \"pandas\"->snowflake-connector-python[pandas]) (1.21.6)\n",
      "Requirement already satisfied: six>=1.5 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas<1.6.0,>=1.0.0; extra == \"pandas\"->snowflake-connector-python[pandas]) (1.16.0)\n",
      "\u001b[31mERROR: azureml-dataset-runtime 1.44.0 has requirement pyarrow<6.0.1,>=0.17.0, but you'll have pyarrow 10.0.1 which is incompatible.\u001b[0m\n",
      "Installing collected packages: pyarrow\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 8.0.0\n",
      "    Uninstalling pyarrow-8.0.0:\n",
      "      Successfully uninstalled pyarrow-8.0.0\n",
      "Successfully installed pyarrow-10.0.1\n",
      "Requirement already satisfied: pyod in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (1.0.4)\n",
      "Requirement already satisfied: joblib in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from pyod) (0.14.1)\n",
      "Requirement already satisfied: six in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from pyod) (1.16.0)\n",
      "Requirement already satisfied: statsmodels in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from pyod) (0.11.0)\n",
      "Requirement already satisfied: scipy>=1.5.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from pyod) (1.5.3)\n",
      "Requirement already satisfied: numba>=0.51 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from pyod) (0.55.2)\n",
      "Requirement already satisfied: matplotlib in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from pyod) (3.2.1)\n",
      "Requirement already satisfied: numpy>=1.19 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from pyod) (1.21.6)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from pyod) (0.22.1)\n",
      "Requirement already satisfied: patsy>=0.5 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from statsmodels->pyod) (0.5.2)\n",
      "Requirement already satisfied: pandas>=0.21 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from statsmodels->pyod) (1.1.5)\n",
      "Requirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from numba>=0.51->pyod) (0.38.1)\n",
      "Requirement already satisfied: setuptools in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from numba>=0.51->pyod) (49.6.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from matplotlib->pyod) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from matplotlib->pyod) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from matplotlib->pyod) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from matplotlib->pyod) (1.4.4)\n",
      "Requirement already satisfied: pytz>=2017.2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from pandas>=0.21->statsmodels->pyod) (2019.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install snowflake-connector-python==3.0.0\n",
    "!pip install pyarrow==8.0.0\n",
    "!pip install azure-keyvault-secrets\n",
    "!pip install pandas\n",
    "!pip install \"snowflake-connector-python[pandas]\"\n",
    "!pip install pyod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d93d18a-8365-46a9-b651-9f84dc6b751e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#On importe les librairies qui vont nous servir pour le traitement de la base de données\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import sklearn #Module de data science / Machine Learning / Analyse prédictive\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "import snowflake.connector\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af49ae54-6d2b-42e5-a56f-c44b39ce91e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.identity import ManagedIdentityCredential, DefaultAzureCredential\n",
    "from azure.keyvault.secrets import SecretClient\n",
    "from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient\n",
    "from azureml.core import Workspace\n",
    "from datetime import datetime,timedelta\n",
    "from scipy import stats\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "440da01a-bfad-44c2-abff-41633ba8c055",
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()\n",
    "keyvault = ws.get_default_keyvault()\n",
    "password = keyvault.get_secret(name=\"YMOLDU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d5fc79b-3e3a-4fd8-a9d9-23619b018611",
   "metadata": {},
   "outputs": [],
   "source": [
    "db= snowflake.connector.connect(\n",
    "                user='ysekal',\n",
    "                password=password,\n",
    "                account='vw51723.west-europe.azure',\n",
    "                warehouse='WH_LAB_STANDARD',\n",
    "                timeout=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bee3ded3-1d19-4f6a-b0d9-c80ce769eb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur = db.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20d927b-9eee-493f-8739-d7337d7a1db1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Création de la table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e108269d-b409-48de-944f-7ca477a3f636",
   "metadata": {},
   "outputs": [],
   "source": [
    "#On appelle la table A_ITEM_SALES_DAILY\n",
    "req = \"\"\" SELECT * from  CHRONODRIVE_PROD.DATA_MART.A_ITEM_SALES_DAILY WHERE to_date(ETL_date) = current_date()-1 \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62d36ac6-0be8-4744-b670-8d4e881c0942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01ab8d01-0201-e955-0000-9f4d04e145c2\n"
     ]
    }
   ],
   "source": [
    "cur.execute(req)\n",
    "print(cur.sfqid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73a933e3-41c8-4236-89e9-13207b56b002",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cur.fetch_pandas_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b343ae-35d8-4e78-ac5c-4efa34ed9825",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Création des tables par types de données "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "968b9c58-4e42-4155-a8b9-2953556c9e5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INVOICE_SHOP_ID</th>\n",
       "      <th>TOTAL_BILL_QUANTITY</th>\n",
       "      <th>TOTAL_ET_AMOUNT</th>\n",
       "      <th>TOTAL_ET_AMOUNT_DISCOUNT_EXCLUDED</th>\n",
       "      <th>TOTAL_ATI_AMOUNT</th>\n",
       "      <th>TOTAL_VAT_AMOUNT</th>\n",
       "      <th>TOTAL_DISCOUNT_ET_AMOUNT</th>\n",
       "      <th>TOTAL_DISCOUNT_ATI_AMOUNT</th>\n",
       "      <th>TOTAL_VIRTUAL_LOT_ET_AMOUNT</th>\n",
       "      <th>TOTAL_VIRTUAL_LOT_ATI_AMOUNT</th>\n",
       "      <th>TOTAL_LOYALTY_ATI_AMOUNT</th>\n",
       "      <th>TOTAL_VIRTUAL_LOT_LOYALTY_ATI_AMOUNT</th>\n",
       "      <th>ITEM_COST</th>\n",
       "      <th>DAILY_AVERAGE_SALE_30_DAYS</th>\n",
       "      <th>DAILY_AVERAGE_SALE_7_DAYS</th>\n",
       "      <th>TOTAL_MARGIN_AMOUNT</th>\n",
       "      <th>TOTAL_MARGIN_AMOUNT_DISCOUNT_EXCLUDED</th>\n",
       "      <th>COST_GOOD_SOLD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1040</td>\n",
       "      <td>1</td>\n",
       "      <td>5.26</td>\n",
       "      <td>5.26</td>\n",
       "      <td>5.55</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.62</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.64</td>\n",
       "      <td>1.64</td>\n",
       "      <td>3.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1047</td>\n",
       "      <td>1</td>\n",
       "      <td>2.66</td>\n",
       "      <td>2.66</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.47</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.19</td>\n",
       "      <td>1.19</td>\n",
       "      <td>1.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1007</td>\n",
       "      <td>1</td>\n",
       "      <td>2.70</td>\n",
       "      <td>2.70</td>\n",
       "      <td>2.85</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.88</td>\n",
       "      <td>1.40</td>\n",
       "      <td>1.57</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.82</td>\n",
       "      <td>1.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1048</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1049</td>\n",
       "      <td>1</td>\n",
       "      <td>2.32</td>\n",
       "      <td>2.32</td>\n",
       "      <td>2.45</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.82</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   INVOICE_SHOP_ID  TOTAL_BILL_QUANTITY  TOTAL_ET_AMOUNT  \\\n",
       "0             1040                    1             5.26   \n",
       "1             1047                    1             2.66   \n",
       "2             1007                    1             2.70   \n",
       "3             1048                    1             1.00   \n",
       "4             1049                    1             2.32   \n",
       "\n",
       "   TOTAL_ET_AMOUNT_DISCOUNT_EXCLUDED  TOTAL_ATI_AMOUNT  TOTAL_VAT_AMOUNT  \\\n",
       "0                               5.26              5.55              0.29   \n",
       "1                               2.66              3.19              0.53   \n",
       "2                               2.70              2.85              0.15   \n",
       "3                               1.00              1.05              0.05   \n",
       "4                               2.32              2.45              0.13   \n",
       "\n",
       "   TOTAL_DISCOUNT_ET_AMOUNT  TOTAL_DISCOUNT_ATI_AMOUNT  \\\n",
       "0                       0.0                        0.0   \n",
       "1                       0.0                        0.0   \n",
       "2                       0.0                        0.0   \n",
       "3                       0.0                        0.0   \n",
       "4                       0.0                        0.0   \n",
       "\n",
       "   TOTAL_VIRTUAL_LOT_ET_AMOUNT  TOTAL_VIRTUAL_LOT_ATI_AMOUNT  \\\n",
       "0                          0.0                           0.0   \n",
       "1                          0.0                           0.0   \n",
       "2                          0.0                           0.0   \n",
       "3                          0.0                           0.0   \n",
       "4                          0.0                           0.0   \n",
       "\n",
       "   TOTAL_LOYALTY_ATI_AMOUNT  TOTAL_VIRTUAL_LOT_LOYALTY_ATI_AMOUNT  ITEM_COST  \\\n",
       "0                       0.0                                   0.0       3.62   \n",
       "1                       0.0                                   0.0       1.47   \n",
       "2                       0.0                                   0.0       1.88   \n",
       "3                       0.0                                   0.0       0.82   \n",
       "4                       0.0                                   0.0       1.82   \n",
       "\n",
       "   DAILY_AVERAGE_SALE_30_DAYS  DAILY_AVERAGE_SALE_7_DAYS  TOTAL_MARGIN_AMOUNT  \\\n",
       "0                        0.60                       0.43                 1.64   \n",
       "1                        0.27                       0.29                 1.19   \n",
       "2                        1.40                       1.57                 0.82   \n",
       "3                        0.97                       0.43                 0.18   \n",
       "4                        1.10                       1.14                 0.50   \n",
       "\n",
       "   TOTAL_MARGIN_AMOUNT_DISCOUNT_EXCLUDED  COST_GOOD_SOLD  \n",
       "0                                   1.64            3.62  \n",
       "1                                   1.19            1.47  \n",
       "2                                   0.82            1.88  \n",
       "3                                   0.18            0.82  \n",
       "4                                   0.50            1.82  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#création de la table avec les données quantitatives \n",
    "df_quanti= df.select_dtypes(exclude= [\"object\",\"datetime64\",\"bool\"])\n",
    "df_quanti.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2429c825-9673-45e8-9f18-2f558078ced3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ITEM_ID</th>\n",
       "      <th>INVOICE_DATE</th>\n",
       "      <th>BBD_FLAG</th>\n",
       "      <th>SALE_TYPE</th>\n",
       "      <th>ETL_SOURCE</th>\n",
       "      <th>ETL_FLOW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52336</td>\n",
       "      <td>2023-04-09</td>\n",
       "      <td>False</td>\n",
       "      <td>MARC</td>\n",
       "      <td>DATA_HUB &amp; F_ORDER_HEADER, F_ORDER_DETAIL, F_I...</td>\n",
       "      <td>MJ_A_DATAHUB_DATAMART_ITEM_SALES_DAILY(2.4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>473526</td>\n",
       "      <td>2023-04-09</td>\n",
       "      <td>False</td>\n",
       "      <td>MARC</td>\n",
       "      <td>DATA_HUB &amp; F_ORDER_HEADER, F_ORDER_DETAIL, F_I...</td>\n",
       "      <td>MJ_A_DATAHUB_DATAMART_ITEM_SALES_DAILY(2.4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>171434</td>\n",
       "      <td>2023-04-09</td>\n",
       "      <td>False</td>\n",
       "      <td>MARC</td>\n",
       "      <td>DATA_HUB &amp; F_ORDER_HEADER, F_ORDER_DETAIL, F_I...</td>\n",
       "      <td>MJ_A_DATAHUB_DATAMART_ITEM_SALES_DAILY(2.4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>194224</td>\n",
       "      <td>2023-04-09</td>\n",
       "      <td>False</td>\n",
       "      <td>MARC</td>\n",
       "      <td>DATA_HUB &amp; F_ORDER_HEADER, F_ORDER_DETAIL, F_I...</td>\n",
       "      <td>MJ_A_DATAHUB_DATAMART_ITEM_SALES_DAILY(2.4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>187291</td>\n",
       "      <td>2023-04-09</td>\n",
       "      <td>False</td>\n",
       "      <td>MARC</td>\n",
       "      <td>DATA_HUB &amp; F_ORDER_HEADER, F_ORDER_DETAIL, F_I...</td>\n",
       "      <td>MJ_A_DATAHUB_DATAMART_ITEM_SALES_DAILY(2.4)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ITEM_ID INVOICE_DATE  BBD_FLAG SALE_TYPE  \\\n",
       "0   52336   2023-04-09     False      MARC   \n",
       "1  473526   2023-04-09     False      MARC   \n",
       "2  171434   2023-04-09     False      MARC   \n",
       "3  194224   2023-04-09     False      MARC   \n",
       "4  187291   2023-04-09     False      MARC   \n",
       "\n",
       "                                          ETL_SOURCE  \\\n",
       "0  DATA_HUB & F_ORDER_HEADER, F_ORDER_DETAIL, F_I...   \n",
       "1  DATA_HUB & F_ORDER_HEADER, F_ORDER_DETAIL, F_I...   \n",
       "2  DATA_HUB & F_ORDER_HEADER, F_ORDER_DETAIL, F_I...   \n",
       "3  DATA_HUB & F_ORDER_HEADER, F_ORDER_DETAIL, F_I...   \n",
       "4  DATA_HUB & F_ORDER_HEADER, F_ORDER_DETAIL, F_I...   \n",
       "\n",
       "                                      ETL_FLOW  \n",
       "0  MJ_A_DATAHUB_DATAMART_ITEM_SALES_DAILY(2.4)  \n",
       "1  MJ_A_DATAHUB_DATAMART_ITEM_SALES_DAILY(2.4)  \n",
       "2  MJ_A_DATAHUB_DATAMART_ITEM_SALES_DAILY(2.4)  \n",
       "3  MJ_A_DATAHUB_DATAMART_ITEM_SALES_DAILY(2.4)  \n",
       "4  MJ_A_DATAHUB_DATAMART_ITEM_SALES_DAILY(2.4)  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#création de la table avec les données qualitatives \n",
    "df_quali= df.select_dtypes(exclude= [\"float64\", \"int16\",\"int64\",\"datetime64\"])\n",
    "df_quali.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6098d4c-ad8f-442f-95e2-3907c7b79503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder les données quali\n",
    "#La fonction get_dummies permet de créer des dummies à partir d'une variable catégorielle: On aura alors un DataFrame avec toutes les catégories encodées de façon binaire\n",
    "warnings.filterwarnings('ignore')\n",
    "df_quali['BBD_FLAG']=pd.get_dummies(df_quali['BBD_FLAG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d33dfb5-1b68-401c-a10b-b1ff44116f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "df_quali['SALE_TYPE']=pd.get_dummies(df_quali['SALE_TYPE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f3b950-0fc3-4e05-9967-93596a885f03",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Aperçu des valeurs statistiques des tables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5392e987-7fb3-48ab-8d6e-5e1db913ebf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INVOICE_SHOP_ID</th>\n",
       "      <th>TOTAL_BILL_QUANTITY</th>\n",
       "      <th>TOTAL_ET_AMOUNT</th>\n",
       "      <th>TOTAL_ET_AMOUNT_DISCOUNT_EXCLUDED</th>\n",
       "      <th>TOTAL_ATI_AMOUNT</th>\n",
       "      <th>TOTAL_VAT_AMOUNT</th>\n",
       "      <th>TOTAL_DISCOUNT_ET_AMOUNT</th>\n",
       "      <th>TOTAL_DISCOUNT_ATI_AMOUNT</th>\n",
       "      <th>TOTAL_VIRTUAL_LOT_ET_AMOUNT</th>\n",
       "      <th>TOTAL_VIRTUAL_LOT_ATI_AMOUNT</th>\n",
       "      <th>TOTAL_LOYALTY_ATI_AMOUNT</th>\n",
       "      <th>TOTAL_VIRTUAL_LOT_LOYALTY_ATI_AMOUNT</th>\n",
       "      <th>ITEM_COST</th>\n",
       "      <th>DAILY_AVERAGE_SALE_30_DAYS</th>\n",
       "      <th>DAILY_AVERAGE_SALE_7_DAYS</th>\n",
       "      <th>TOTAL_MARGIN_AMOUNT</th>\n",
       "      <th>TOTAL_MARGIN_AMOUNT_DISCOUNT_EXCLUDED</th>\n",
       "      <th>COST_GOOD_SOLD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>419690.000000</td>\n",
       "      <td>419690.000000</td>\n",
       "      <td>419690.000000</td>\n",
       "      <td>419690.000000</td>\n",
       "      <td>419690.000000</td>\n",
       "      <td>419690.000000</td>\n",
       "      <td>419690.000000</td>\n",
       "      <td>419690.000000</td>\n",
       "      <td>419690.000000</td>\n",
       "      <td>419690.000000</td>\n",
       "      <td>419690.000000</td>\n",
       "      <td>419690.000000</td>\n",
       "      <td>419234.000000</td>\n",
       "      <td>419690.000000</td>\n",
       "      <td>419690.000000</td>\n",
       "      <td>419690.000000</td>\n",
       "      <td>419690.000000</td>\n",
       "      <td>419690.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1032.309326</td>\n",
       "      <td>2.607239</td>\n",
       "      <td>7.272318</td>\n",
       "      <td>7.600857</td>\n",
       "      <td>7.876432</td>\n",
       "      <td>0.624148</td>\n",
       "      <td>0.143196</td>\n",
       "      <td>0.157736</td>\n",
       "      <td>0.203238</td>\n",
       "      <td>0.223271</td>\n",
       "      <td>0.021852</td>\n",
       "      <td>0.025294</td>\n",
       "      <td>2.534244</td>\n",
       "      <td>2.293046</td>\n",
       "      <td>2.370136</td>\n",
       "      <td>1.355876</td>\n",
       "      <td>1.683498</td>\n",
       "      <td>5.908002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>20.745012</td>\n",
       "      <td>3.966275</td>\n",
       "      <td>10.479182</td>\n",
       "      <td>11.253910</td>\n",
       "      <td>11.434270</td>\n",
       "      <td>1.265262</td>\n",
       "      <td>1.207121</td>\n",
       "      <td>1.375507</td>\n",
       "      <td>1.493601</td>\n",
       "      <td>1.653736</td>\n",
       "      <td>0.391092</td>\n",
       "      <td>0.402227</td>\n",
       "      <td>4.082558</td>\n",
       "      <td>3.947620</td>\n",
       "      <td>4.077977</td>\n",
       "      <td>4.417616</td>\n",
       "      <td>4.325992</td>\n",
       "      <td>10.161382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1001.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2014.680000</td>\n",
       "      <td>-2014.680000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1016.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.560000</td>\n",
       "      <td>2.610000</td>\n",
       "      <td>2.790000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.340000</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>1.890000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1032.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.310000</td>\n",
       "      <td>4.450000</td>\n",
       "      <td>4.690000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.910000</td>\n",
       "      <td>1.030000</td>\n",
       "      <td>1.140000</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>3.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1047.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.060000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>8.750000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.840000</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>2.710000</td>\n",
       "      <td>1.740000</td>\n",
       "      <td>1.960000</td>\n",
       "      <td>6.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1077.000000</td>\n",
       "      <td>318.000000</td>\n",
       "      <td>1416.600000</td>\n",
       "      <td>1696.600000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>283.400000</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>420.000000</td>\n",
       "      <td>127.500000</td>\n",
       "      <td>153.090000</td>\n",
       "      <td>51.290000</td>\n",
       "      <td>57.600000</td>\n",
       "      <td>2023.050000</td>\n",
       "      <td>192.000000</td>\n",
       "      <td>206.860000</td>\n",
       "      <td>185.830000</td>\n",
       "      <td>185.830000</td>\n",
       "      <td>2023.050000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       INVOICE_SHOP_ID  TOTAL_BILL_QUANTITY  TOTAL_ET_AMOUNT  \\\n",
       "count    419690.000000        419690.000000    419690.000000   \n",
       "mean       1032.309326             2.607239         7.272318   \n",
       "std          20.745012             3.966275        10.479182   \n",
       "min        1001.000000             0.000000        -0.050000   \n",
       "25%        1016.000000             1.000000         2.560000   \n",
       "50%        1032.000000             2.000000         4.310000   \n",
       "75%        1047.000000             3.000000         8.060000   \n",
       "max        1077.000000           318.000000      1416.600000   \n",
       "\n",
       "       TOTAL_ET_AMOUNT_DISCOUNT_EXCLUDED  TOTAL_ATI_AMOUNT  TOTAL_VAT_AMOUNT  \\\n",
       "count                      419690.000000     419690.000000     419690.000000   \n",
       "mean                            7.600857          7.876432          0.624148   \n",
       "std                            11.253910         11.434270          1.265262   \n",
       "min                             0.000000         -0.050000          0.000000   \n",
       "25%                             2.610000          2.790000          0.160000   \n",
       "50%                             4.450000          4.690000          0.300000   \n",
       "75%                             8.400000          8.750000          0.640000   \n",
       "max                          1696.600000       1700.000000        283.400000   \n",
       "\n",
       "       TOTAL_DISCOUNT_ET_AMOUNT  TOTAL_DISCOUNT_ATI_AMOUNT  \\\n",
       "count             419690.000000              419690.000000   \n",
       "mean                   0.143196                   0.157736   \n",
       "std                    1.207121                   1.375507   \n",
       "min                    0.000000                   0.000000   \n",
       "25%                    0.000000                   0.000000   \n",
       "50%                    0.000000                   0.000000   \n",
       "75%                    0.000000                   0.000000   \n",
       "max                  350.000000                 420.000000   \n",
       "\n",
       "       TOTAL_VIRTUAL_LOT_ET_AMOUNT  TOTAL_VIRTUAL_LOT_ATI_AMOUNT  \\\n",
       "count                419690.000000                 419690.000000   \n",
       "mean                      0.203238                      0.223271   \n",
       "std                       1.493601                      1.653736   \n",
       "min                       0.000000                      0.000000   \n",
       "25%                       0.000000                      0.000000   \n",
       "50%                       0.000000                      0.000000   \n",
       "75%                       0.000000                      0.000000   \n",
       "max                     127.500000                    153.090000   \n",
       "\n",
       "       TOTAL_LOYALTY_ATI_AMOUNT  TOTAL_VIRTUAL_LOT_LOYALTY_ATI_AMOUNT  \\\n",
       "count             419690.000000                         419690.000000   \n",
       "mean                   0.021852                              0.025294   \n",
       "std                    0.391092                              0.402227   \n",
       "min                    0.000000                              0.000000   \n",
       "25%                    0.000000                              0.000000   \n",
       "50%                    0.000000                              0.000000   \n",
       "75%                    0.000000                              0.000000   \n",
       "max                   51.290000                             57.600000   \n",
       "\n",
       "           ITEM_COST  DAILY_AVERAGE_SALE_30_DAYS  DAILY_AVERAGE_SALE_7_DAYS  \\\n",
       "count  419234.000000               419690.000000              419690.000000   \n",
       "mean        2.534244                    2.293046                   2.370136   \n",
       "std         4.082558                    3.947620                   4.077977   \n",
       "min         0.000000                    0.000000                   0.000000   \n",
       "25%         1.340000                    0.940000                   0.860000   \n",
       "50%         1.910000                    1.030000                   1.140000   \n",
       "75%         2.840000                    2.700000                   2.710000   \n",
       "max      2023.050000                  192.000000                 206.860000   \n",
       "\n",
       "       TOTAL_MARGIN_AMOUNT  TOTAL_MARGIN_AMOUNT_DISCOUNT_EXCLUDED  \\\n",
       "count        419690.000000                          419690.000000   \n",
       "mean              1.355876                               1.683498   \n",
       "std               4.417616                               4.325992   \n",
       "min           -2014.680000                           -2014.680000   \n",
       "25%               0.380000                               0.480000   \n",
       "50%               0.870000                               0.990000   \n",
       "75%               1.740000                               1.960000   \n",
       "max             185.830000                             185.830000   \n",
       "\n",
       "       COST_GOOD_SOLD  \n",
       "count   419690.000000  \n",
       "mean         5.908002  \n",
       "std         10.161382  \n",
       "min          0.000000  \n",
       "25%          1.890000  \n",
       "50%          3.300000  \n",
       "75%          6.420000  \n",
       "max       2023.050000  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7760e4a2-c164-4779-ab73-8b35eefadc11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INVOICE_SHOP_ID</th>\n",
       "      <th>TOTAL_BILL_QUANTITY</th>\n",
       "      <th>TOTAL_ET_AMOUNT</th>\n",
       "      <th>TOTAL_ET_AMOUNT_DISCOUNT_EXCLUDED</th>\n",
       "      <th>TOTAL_ATI_AMOUNT</th>\n",
       "      <th>TOTAL_VAT_AMOUNT</th>\n",
       "      <th>TOTAL_DISCOUNT_ET_AMOUNT</th>\n",
       "      <th>TOTAL_DISCOUNT_ATI_AMOUNT</th>\n",
       "      <th>TOTAL_VIRTUAL_LOT_ET_AMOUNT</th>\n",
       "      <th>TOTAL_VIRTUAL_LOT_ATI_AMOUNT</th>\n",
       "      <th>TOTAL_LOYALTY_ATI_AMOUNT</th>\n",
       "      <th>TOTAL_VIRTUAL_LOT_LOYALTY_ATI_AMOUNT</th>\n",
       "      <th>ITEM_COST</th>\n",
       "      <th>DAILY_AVERAGE_SALE_30_DAYS</th>\n",
       "      <th>DAILY_AVERAGE_SALE_7_DAYS</th>\n",
       "      <th>TOTAL_MARGIN_AMOUNT</th>\n",
       "      <th>TOTAL_MARGIN_AMOUNT_DISCOUNT_EXCLUDED</th>\n",
       "      <th>COST_GOOD_SOLD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>419690.000000</td>\n",
       "      <td>419690.000000</td>\n",
       "      <td>419690.000000</td>\n",
       "      <td>419690.000000</td>\n",
       "      <td>419690.000000</td>\n",
       "      <td>419690.000000</td>\n",
       "      <td>419690.000000</td>\n",
       "      <td>419690.000000</td>\n",
       "      <td>419690.000000</td>\n",
       "      <td>419690.000000</td>\n",
       "      <td>419690.000000</td>\n",
       "      <td>419690.000000</td>\n",
       "      <td>419234.000000</td>\n",
       "      <td>419690.000000</td>\n",
       "      <td>419690.000000</td>\n",
       "      <td>419690.000000</td>\n",
       "      <td>419690.000000</td>\n",
       "      <td>419690.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1032.309326</td>\n",
       "      <td>2.607239</td>\n",
       "      <td>7.272318</td>\n",
       "      <td>7.600857</td>\n",
       "      <td>7.876432</td>\n",
       "      <td>0.624148</td>\n",
       "      <td>0.143196</td>\n",
       "      <td>0.157736</td>\n",
       "      <td>0.203238</td>\n",
       "      <td>0.223271</td>\n",
       "      <td>0.021852</td>\n",
       "      <td>0.025294</td>\n",
       "      <td>2.534244</td>\n",
       "      <td>2.293046</td>\n",
       "      <td>2.370136</td>\n",
       "      <td>1.355876</td>\n",
       "      <td>1.683498</td>\n",
       "      <td>5.908002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>20.745012</td>\n",
       "      <td>3.966275</td>\n",
       "      <td>10.479182</td>\n",
       "      <td>11.253910</td>\n",
       "      <td>11.434270</td>\n",
       "      <td>1.265262</td>\n",
       "      <td>1.207121</td>\n",
       "      <td>1.375507</td>\n",
       "      <td>1.493601</td>\n",
       "      <td>1.653736</td>\n",
       "      <td>0.391092</td>\n",
       "      <td>0.402227</td>\n",
       "      <td>4.082558</td>\n",
       "      <td>3.947620</td>\n",
       "      <td>4.077977</td>\n",
       "      <td>4.417616</td>\n",
       "      <td>4.325992</td>\n",
       "      <td>10.161382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1001.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2014.680000</td>\n",
       "      <td>-2014.680000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1016.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.560000</td>\n",
       "      <td>2.610000</td>\n",
       "      <td>2.790000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.340000</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>1.890000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1032.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.310000</td>\n",
       "      <td>4.450000</td>\n",
       "      <td>4.690000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.910000</td>\n",
       "      <td>1.030000</td>\n",
       "      <td>1.140000</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>3.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1047.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.060000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>8.750000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.840000</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>2.710000</td>\n",
       "      <td>1.740000</td>\n",
       "      <td>1.960000</td>\n",
       "      <td>6.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1077.000000</td>\n",
       "      <td>318.000000</td>\n",
       "      <td>1416.600000</td>\n",
       "      <td>1696.600000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>283.400000</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>420.000000</td>\n",
       "      <td>127.500000</td>\n",
       "      <td>153.090000</td>\n",
       "      <td>51.290000</td>\n",
       "      <td>57.600000</td>\n",
       "      <td>2023.050000</td>\n",
       "      <td>192.000000</td>\n",
       "      <td>206.860000</td>\n",
       "      <td>185.830000</td>\n",
       "      <td>185.830000</td>\n",
       "      <td>2023.050000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       INVOICE_SHOP_ID  TOTAL_BILL_QUANTITY  TOTAL_ET_AMOUNT  \\\n",
       "count    419690.000000        419690.000000    419690.000000   \n",
       "mean       1032.309326             2.607239         7.272318   \n",
       "std          20.745012             3.966275        10.479182   \n",
       "min        1001.000000             0.000000        -0.050000   \n",
       "25%        1016.000000             1.000000         2.560000   \n",
       "50%        1032.000000             2.000000         4.310000   \n",
       "75%        1047.000000             3.000000         8.060000   \n",
       "max        1077.000000           318.000000      1416.600000   \n",
       "\n",
       "       TOTAL_ET_AMOUNT_DISCOUNT_EXCLUDED  TOTAL_ATI_AMOUNT  TOTAL_VAT_AMOUNT  \\\n",
       "count                      419690.000000     419690.000000     419690.000000   \n",
       "mean                            7.600857          7.876432          0.624148   \n",
       "std                            11.253910         11.434270          1.265262   \n",
       "min                             0.000000         -0.050000          0.000000   \n",
       "25%                             2.610000          2.790000          0.160000   \n",
       "50%                             4.450000          4.690000          0.300000   \n",
       "75%                             8.400000          8.750000          0.640000   \n",
       "max                          1696.600000       1700.000000        283.400000   \n",
       "\n",
       "       TOTAL_DISCOUNT_ET_AMOUNT  TOTAL_DISCOUNT_ATI_AMOUNT  \\\n",
       "count             419690.000000              419690.000000   \n",
       "mean                   0.143196                   0.157736   \n",
       "std                    1.207121                   1.375507   \n",
       "min                    0.000000                   0.000000   \n",
       "25%                    0.000000                   0.000000   \n",
       "50%                    0.000000                   0.000000   \n",
       "75%                    0.000000                   0.000000   \n",
       "max                  350.000000                 420.000000   \n",
       "\n",
       "       TOTAL_VIRTUAL_LOT_ET_AMOUNT  TOTAL_VIRTUAL_LOT_ATI_AMOUNT  \\\n",
       "count                419690.000000                 419690.000000   \n",
       "mean                      0.203238                      0.223271   \n",
       "std                       1.493601                      1.653736   \n",
       "min                       0.000000                      0.000000   \n",
       "25%                       0.000000                      0.000000   \n",
       "50%                       0.000000                      0.000000   \n",
       "75%                       0.000000                      0.000000   \n",
       "max                     127.500000                    153.090000   \n",
       "\n",
       "       TOTAL_LOYALTY_ATI_AMOUNT  TOTAL_VIRTUAL_LOT_LOYALTY_ATI_AMOUNT  \\\n",
       "count             419690.000000                         419690.000000   \n",
       "mean                   0.021852                              0.025294   \n",
       "std                    0.391092                              0.402227   \n",
       "min                    0.000000                              0.000000   \n",
       "25%                    0.000000                              0.000000   \n",
       "50%                    0.000000                              0.000000   \n",
       "75%                    0.000000                              0.000000   \n",
       "max                   51.290000                             57.600000   \n",
       "\n",
       "           ITEM_COST  DAILY_AVERAGE_SALE_30_DAYS  DAILY_AVERAGE_SALE_7_DAYS  \\\n",
       "count  419234.000000               419690.000000              419690.000000   \n",
       "mean        2.534244                    2.293046                   2.370136   \n",
       "std         4.082558                    3.947620                   4.077977   \n",
       "min         0.000000                    0.000000                   0.000000   \n",
       "25%         1.340000                    0.940000                   0.860000   \n",
       "50%         1.910000                    1.030000                   1.140000   \n",
       "75%         2.840000                    2.700000                   2.710000   \n",
       "max      2023.050000                  192.000000                 206.860000   \n",
       "\n",
       "       TOTAL_MARGIN_AMOUNT  TOTAL_MARGIN_AMOUNT_DISCOUNT_EXCLUDED  \\\n",
       "count        419690.000000                          419690.000000   \n",
       "mean              1.355876                               1.683498   \n",
       "std               4.417616                               4.325992   \n",
       "min           -2014.680000                           -2014.680000   \n",
       "25%               0.380000                               0.480000   \n",
       "50%               0.870000                               0.990000   \n",
       "75%               1.740000                               1.960000   \n",
       "max             185.830000                             185.830000   \n",
       "\n",
       "       COST_GOOD_SOLD  \n",
       "count   419690.000000  \n",
       "mean         5.908002  \n",
       "std         10.161382  \n",
       "min          0.000000  \n",
       "25%          1.890000  \n",
       "50%          3.300000  \n",
       "75%          6.420000  \n",
       "max       2023.050000  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_quanti.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b22de6b-34a6-40cc-985d-0b24216cc944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BBD_FLAG</th>\n",
       "      <th>SALE_TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>419690.000000</td>\n",
       "      <td>419690.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.981744</td>\n",
       "      <td>0.000105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.133877</td>\n",
       "      <td>0.010239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            BBD_FLAG      SALE_TYPE\n",
       "count  419690.000000  419690.000000\n",
       "mean        0.981744       0.000105\n",
       "std         0.133877       0.010239\n",
       "min         0.000000       0.000000\n",
       "25%         1.000000       0.000000\n",
       "50%         1.000000       0.000000\n",
       "75%         1.000000       0.000000\n",
       "max         1.000000       1.000000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_quali.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ee56a23a-c727-4309-8ec8-89703b68ecc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 419690 entries, 0 to 419689\n",
      "Data columns (total 25 columns):\n",
      " #   Column                                 Non-Null Count   Dtype         \n",
      "---  ------                                 --------------   -----         \n",
      " 0   INVOICE_SHOP_ID                        419690 non-null  int16         \n",
      " 1   ITEM_ID                                419690 non-null  object        \n",
      " 2   INVOICE_DATE                           419690 non-null  object        \n",
      " 3   TOTAL_BILL_QUANTITY                    419690 non-null  int16         \n",
      " 4   TOTAL_ET_AMOUNT                        419690 non-null  float64       \n",
      " 5   TOTAL_ET_AMOUNT_DISCOUNT_EXCLUDED      419690 non-null  float64       \n",
      " 6   TOTAL_ATI_AMOUNT                       419690 non-null  float64       \n",
      " 7   TOTAL_VAT_AMOUNT                       419690 non-null  float64       \n",
      " 8   TOTAL_DISCOUNT_ET_AMOUNT               419690 non-null  float64       \n",
      " 9   TOTAL_DISCOUNT_ATI_AMOUNT              419690 non-null  float64       \n",
      " 10  TOTAL_VIRTUAL_LOT_ET_AMOUNT            419690 non-null  float64       \n",
      " 11  TOTAL_VIRTUAL_LOT_ATI_AMOUNT           419690 non-null  float64       \n",
      " 12  TOTAL_LOYALTY_ATI_AMOUNT               419690 non-null  float64       \n",
      " 13  TOTAL_VIRTUAL_LOT_LOYALTY_ATI_AMOUNT   419690 non-null  float64       \n",
      " 14  ITEM_COST                              419234 non-null  float64       \n",
      " 15  BBD_FLAG                               419690 non-null  bool          \n",
      " 16  SALE_TYPE                              419690 non-null  object        \n",
      " 17  DAILY_AVERAGE_SALE_30_DAYS             419690 non-null  float64       \n",
      " 18  DAILY_AVERAGE_SALE_7_DAYS              419690 non-null  float64       \n",
      " 19  TOTAL_MARGIN_AMOUNT                    419690 non-null  float64       \n",
      " 20  TOTAL_MARGIN_AMOUNT_DISCOUNT_EXCLUDED  419690 non-null  float64       \n",
      " 21  COST_GOOD_SOLD                         419690 non-null  float64       \n",
      " 22  ETL_SOURCE                             419690 non-null  object        \n",
      " 23  ETL_DATE                               419690 non-null  datetime64[ns]\n",
      " 24  ETL_FLOW                               419690 non-null  object        \n",
      "dtypes: bool(1), datetime64[ns](1), float64(16), int16(2), object(5)\n",
      "memory usage: 72.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d5b4d5-3955-42c3-bd88-9af416e7377d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Gestion des valeurs manquantes "
   ]
  },
  {
   "cell_type": "raw",
   "id": "cc91103b-391c-4103-9eee-80bbcd1e0727",
   "metadata": {},
   "source": [
    "# Créer une nouvelle fonction qui détermine si la valeur en paramètre est manquante:\n",
    "def num_missing(x):\n",
    "    return sum(x.isnull())\n",
    "# On applique cette fonction pour chaque colonne:\n",
    "print(\"Valeurs manquantes par colonne:\")\n",
    "print(df.apply(num_missing, axis=0)) #axis=0 définit que la fonction sera bien appliquée sur chaque colonne\n",
    "# Puis application pour chaque ligne:\n",
    "print(\"\\nValeurs manquantes par ligne:\")\n",
    "print(df.apply(num_missing, axis=1).head()) #axis=1 définit que la fonction sera bien appliquée sur chaque ligne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "24c4b312-7399-4d67-96ab-94d5602d8a2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Valeurs manquantes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ITEM_COST</th>\n",
       "      <td>456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Valeurs manquantes\n",
       "ITEM_COST                 456"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Faire apparaitre sous forme de tableau les valeurs manquantes\n",
    "dfVM=df_quanti.isnull().sum()\n",
    "dfVM = dfVM.drop(dfVM[dfVM == 0].index).sort_values(ascending=False)\n",
    "missing_data = pd.DataFrame({'Valeurs manquantes' : dfVM})\n",
    "missing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bfa92041-5de7-4c30-afc9-cb9e8080d89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remplacement des valeurs null par les valeurs médian.\n",
    "df_quanti['ITEM_COST'] = df_quanti['ITEM_COST'].fillna(df_quanti['ITEM_COST'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dea77dd3-611b-4971-9016-5bb8ce41071a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Valeurs manquantes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Valeurs manquantes]\n",
       "Index: []"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Faire apparaitre sous forme de tableau les valeurs manquantes\n",
    "dfVM=df_quanti.isnull().sum()\n",
    "dfVM = dfVM.drop(dfVM[dfVM == 0].index).sort_values(ascending=False)\n",
    "missing_data = pd.DataFrame({'Valeurs manquantes' : dfVM})\n",
    "missing_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c4a60c-7f5c-405c-9e4b-158d6396331d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Valeurs négatives\n",
    "\n",
    "On veut mettre dans cette liste toutes les colonnes où les données ne doivent pas être négatives.  \n",
    "**Point d'attention** : il y a des colonnes qui auront des valeurs négatives comme valeurs 'normales'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "95186f0d-e0b2-421b-8f06-b23b05aeb9c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TOTAL_ET_AMOUNT', 'TOTAL_ATI_AMOUNT', 'TOTAL_MARGIN_AMOUNT', 'TOTAL_MARGIN_AMOUNT_DISCOUNT_EXCLUDED']\n"
     ]
    }
   ],
   "source": [
    "liste_col_negative = []\n",
    "for cols in df_quanti:\n",
    "    if ((df_quanti[cols]<0).sum())>0:\n",
    "        liste_col_negative.append(cols)\n",
    "print(liste_col_negative)       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da677f0-00c3-46ad-8296-4a97a5c3cd42",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Outliers données qualitatives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d911a8-bb67-4480-88b3-4a04ea77d2fa",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Gestion de la qualité du format date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cb7f556f-3b5f-401c-bc46-9f649dd821fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_errors = []\n",
    "list_date = df_quali[\"INVOICE_DATE\"].tolist()\n",
    "for date in list_date:\n",
    "    try:\n",
    "        datetime.strftime(date, '%Y-%m-%d')\n",
    "    except ValueError:\n",
    "        list_errors.append(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "798f51b7-72f4-478a-b263-eec47dc33e9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ITEM_ID</th>\n",
       "      <th>INVOICE_DATE</th>\n",
       "      <th>BBD_FLAG</th>\n",
       "      <th>SALE_TYPE</th>\n",
       "      <th>ETL_SOURCE</th>\n",
       "      <th>ETL_FLOW</th>\n",
       "      <th>validate_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52336</td>\n",
       "      <td>2023-04-09</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>DATA_HUB &amp; F_ORDER_HEADER, F_ORDER_DETAIL, F_I...</td>\n",
       "      <td>MJ_A_DATAHUB_DATAMART_ITEM_SALES_DAILY(2.4)</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>473526</td>\n",
       "      <td>2023-04-09</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>DATA_HUB &amp; F_ORDER_HEADER, F_ORDER_DETAIL, F_I...</td>\n",
       "      <td>MJ_A_DATAHUB_DATAMART_ITEM_SALES_DAILY(2.4)</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>171434</td>\n",
       "      <td>2023-04-09</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>DATA_HUB &amp; F_ORDER_HEADER, F_ORDER_DETAIL, F_I...</td>\n",
       "      <td>MJ_A_DATAHUB_DATAMART_ITEM_SALES_DAILY(2.4)</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>194224</td>\n",
       "      <td>2023-04-09</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>DATA_HUB &amp; F_ORDER_HEADER, F_ORDER_DETAIL, F_I...</td>\n",
       "      <td>MJ_A_DATAHUB_DATAMART_ITEM_SALES_DAILY(2.4)</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>187291</td>\n",
       "      <td>2023-04-09</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>DATA_HUB &amp; F_ORDER_HEADER, F_ORDER_DETAIL, F_I...</td>\n",
       "      <td>MJ_A_DATAHUB_DATAMART_ITEM_SALES_DAILY(2.4)</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ITEM_ID INVOICE_DATE  BBD_FLAG  SALE_TYPE  \\\n",
       "0   52336   2023-04-09         1          0   \n",
       "1  473526   2023-04-09         1          0   \n",
       "2  171434   2023-04-09         1          0   \n",
       "3  194224   2023-04-09         1          0   \n",
       "4  187291   2023-04-09         1          0   \n",
       "\n",
       "                                          ETL_SOURCE  \\\n",
       "0  DATA_HUB & F_ORDER_HEADER, F_ORDER_DETAIL, F_I...   \n",
       "1  DATA_HUB & F_ORDER_HEADER, F_ORDER_DETAIL, F_I...   \n",
       "2  DATA_HUB & F_ORDER_HEADER, F_ORDER_DETAIL, F_I...   \n",
       "3  DATA_HUB & F_ORDER_HEADER, F_ORDER_DETAIL, F_I...   \n",
       "4  DATA_HUB & F_ORDER_HEADER, F_ORDER_DETAIL, F_I...   \n",
       "\n",
       "                                      ETL_FLOW  validate_date  \n",
       "0  MJ_A_DATAHUB_DATAMART_ITEM_SALES_DAILY(2.4)           True  \n",
       "1  MJ_A_DATAHUB_DATAMART_ITEM_SALES_DAILY(2.4)           True  \n",
       "2  MJ_A_DATAHUB_DATAMART_ITEM_SALES_DAILY(2.4)           True  \n",
       "3  MJ_A_DATAHUB_DATAMART_ITEM_SALES_DAILY(2.4)           True  \n",
       "4  MJ_A_DATAHUB_DATAMART_ITEM_SALES_DAILY(2.4)           True  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_quali['validate_date'] = np.where(df_quali['INVOICE_DATE'] in list_errors, False, True)\n",
    "df_quali.head()\n",
    "#df_quali[df_quali['validate_date']==False] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "748af296-d733-4346-94fd-0872ae30ee99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ITEM_ID</th>\n",
       "      <th>INVOICE_DATE</th>\n",
       "      <th>BBD_FLAG</th>\n",
       "      <th>SALE_TYPE</th>\n",
       "      <th>ETL_SOURCE</th>\n",
       "      <th>ETL_FLOW</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validate_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>419690</td>\n",
       "      <td>419690</td>\n",
       "      <td>419690</td>\n",
       "      <td>419690</td>\n",
       "      <td>419690</td>\n",
       "      <td>419690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ITEM_ID  INVOICE_DATE  BBD_FLAG  SALE_TYPE  ETL_SOURCE  \\\n",
       "validate_date                                                           \n",
       "True            419690        419690    419690     419690      419690   \n",
       "\n",
       "               ETL_FLOW  \n",
       "validate_date            \n",
       "True             419690  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_quali.groupby('validate_date').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063a1586-cc97-4a69-87a2-7e337ad05ab9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Gestion de la qualité du format ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1a642954-5832-4dc7-8ab0-32f1f616784c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 419690 entries, 0 to 419689\n",
      "Data columns (total 25 columns):\n",
      " #   Column                                 Non-Null Count   Dtype         \n",
      "---  ------                                 --------------   -----         \n",
      " 0   INVOICE_SHOP_ID                        419690 non-null  int16         \n",
      " 1   ITEM_ID                                419690 non-null  object        \n",
      " 2   INVOICE_DATE                           419690 non-null  object        \n",
      " 3   TOTAL_BILL_QUANTITY                    419690 non-null  int16         \n",
      " 4   TOTAL_ET_AMOUNT                        419690 non-null  float64       \n",
      " 5   TOTAL_ET_AMOUNT_DISCOUNT_EXCLUDED      419690 non-null  float64       \n",
      " 6   TOTAL_ATI_AMOUNT                       419690 non-null  float64       \n",
      " 7   TOTAL_VAT_AMOUNT                       419690 non-null  float64       \n",
      " 8   TOTAL_DISCOUNT_ET_AMOUNT               419690 non-null  float64       \n",
      " 9   TOTAL_DISCOUNT_ATI_AMOUNT              419690 non-null  float64       \n",
      " 10  TOTAL_VIRTUAL_LOT_ET_AMOUNT            419690 non-null  float64       \n",
      " 11  TOTAL_VIRTUAL_LOT_ATI_AMOUNT           419690 non-null  float64       \n",
      " 12  TOTAL_LOYALTY_ATI_AMOUNT               419690 non-null  float64       \n",
      " 13  TOTAL_VIRTUAL_LOT_LOYALTY_ATI_AMOUNT   419690 non-null  float64       \n",
      " 14  ITEM_COST                              419234 non-null  float64       \n",
      " 15  BBD_FLAG                               419690 non-null  bool          \n",
      " 16  SALE_TYPE                              419690 non-null  object        \n",
      " 17  DAILY_AVERAGE_SALE_30_DAYS             419690 non-null  float64       \n",
      " 18  DAILY_AVERAGE_SALE_7_DAYS              419690 non-null  float64       \n",
      " 19  TOTAL_MARGIN_AMOUNT                    419690 non-null  float64       \n",
      " 20  TOTAL_MARGIN_AMOUNT_DISCOUNT_EXCLUDED  419690 non-null  float64       \n",
      " 21  COST_GOOD_SOLD                         419690 non-null  float64       \n",
      " 22  ETL_SOURCE                             419690 non-null  object        \n",
      " 23  ETL_DATE                               419690 non-null  datetime64[ns]\n",
      " 24  ETL_FLOW                               419690 non-null  object        \n",
      "dtypes: bool(1), datetime64[ns](1), float64(16), int16(2), object(5)\n",
      "memory usage: 72.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "744b0104-856e-4f5a-a94c-b38777232752",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Liste des colonnes \n",
    "df_list= list(df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a190c055-25c4-4104-bcba-6a384e4dfc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = pd.DataFrame(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b8113653-72c8-476d-bf90-6cf1e9aa8423",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list=df_list.rename(columns=\n",
    "               {0:'colname'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "69fc8d2e-6ea8-468b-b3e3-4993e86811e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_id = df_list[df_list['colname'].str.contains('ID')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b8e6db0c-199a-42b6-b777-e9f896a384e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_id = list(df_id.colname.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e276ab98-4e9a-41a5-b021-54391105f51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in list_id :\n",
    "    for columns in df.columns :\n",
    "        if columns == i :\n",
    "            df[columns] = df[columns].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3a9d462c-7d16-4190-afb8-34513fc87c54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "INVOICE_SHOP_ID                                  object\n",
       "ITEM_ID                                          object\n",
       "INVOICE_DATE                                     object\n",
       "TOTAL_BILL_QUANTITY                               int16\n",
       "TOTAL_ET_AMOUNT                                 float64\n",
       "TOTAL_ET_AMOUNT_DISCOUNT_EXCLUDED               float64\n",
       "TOTAL_ATI_AMOUNT                                float64\n",
       "TOTAL_VAT_AMOUNT                                float64\n",
       "TOTAL_DISCOUNT_ET_AMOUNT                        float64\n",
       "TOTAL_DISCOUNT_ATI_AMOUNT                       float64\n",
       "TOTAL_VIRTUAL_LOT_ET_AMOUNT                     float64\n",
       "TOTAL_VIRTUAL_LOT_ATI_AMOUNT                    float64\n",
       "TOTAL_LOYALTY_ATI_AMOUNT                        float64\n",
       "TOTAL_VIRTUAL_LOT_LOYALTY_ATI_AMOUNT            float64\n",
       "ITEM_COST                                       float64\n",
       "BBD_FLAG                                           bool\n",
       "SALE_TYPE                                        object\n",
       "DAILY_AVERAGE_SALE_30_DAYS                      float64\n",
       "DAILY_AVERAGE_SALE_7_DAYS                       float64\n",
       "TOTAL_MARGIN_AMOUNT                             float64\n",
       "TOTAL_MARGIN_AMOUNT_DISCOUNT_EXCLUDED           float64\n",
       "COST_GOOD_SOLD                                  float64\n",
       "ETL_SOURCE                                       object\n",
       "ETL_DATE                                 datetime64[ns]\n",
       "ETL_FLOW                                         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "682a9f87-13cd-4e98-94f1-f51026fcaaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_errors = []\n",
    "for i in list_id:\n",
    "    try:\n",
    "        df[i].str.contains('\\d{4,6}')\n",
    "    except ValueError:\n",
    "        list_errors.append(i)\n",
    "df['validate_id'] = np.where(df[i] in list_errors, False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "89be5b8d-cca2-4f7f-9aa2-e018f0dd4516",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'validate_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [41]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf_quali\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalidate_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcount()\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/pandas/core/frame.py:6515\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed, dropna)\u001b[0m\n\u001b[1;32m   6512\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to supply one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mby\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6513\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis_number(axis)\n\u001b[0;32m-> 6515\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   6516\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6518\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6519\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6520\u001b[0m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6521\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6522\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6523\u001b[0m \u001b[43m    \u001b[49m\u001b[43msqueeze\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6524\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6525\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6526\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/pandas/core/groupby/groupby.py:525\u001b[0m, in \u001b[0;36m_GroupBy.__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, mutated, dropna)\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    523\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgroupby\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgrouper\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_grouper\n\u001b[0;32m--> 525\u001b[0m     grouper, exclusions, obj \u001b[38;5;241m=\u001b[39m \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmutated\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmutated\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    534\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj \u001b[38;5;241m=\u001b[39m obj\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_get_axis_number(axis)\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/pandas/core/groupby/grouper.py:786\u001b[0m, in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, mutated, validate, dropna)\u001b[0m\n\u001b[1;32m    784\u001b[0m         in_axis, name, level, gpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    785\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 786\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[1;32m    787\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    788\u001b[0m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[1;32m    789\u001b[0m     exclusions\u001b[38;5;241m.\u001b[39mappend(gpr\u001b[38;5;241m.\u001b[39mkey)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'validate_id'"
     ]
    }
   ],
   "source": [
    "df_quali.groupby('validate_id').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da473f4-ce75-4f4b-937c-44c6c92784cc",
   "metadata": {},
   "source": [
    "# Outliers données quantitatives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac39b41e-ca0c-4673-9dc4-7b13f3b034fa",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3121ba5-a092-4bf1-8d2b-888f2e3d8db7",
   "metadata": {},
   "source": [
    "Pourquoi et comment rechercher les valeurs aberrantes\n",
    "De nombreux algorithmes d'apprentissage automatique et modèles de régression sont sensibles aux valeurs aberrantes. Une valeur aberrante est un point de données qui s'écarte considérablement des autres points. Si elles ne sont pas correctement prises en compte, les déductions obtenues à partir des modèles statistiques utilisés risquent de ne pas être utiles.\n",
    "\n",
    "Il existe de nombreuses méthodes populaires pour détecter les valeurs aberrantes, à savoir les méthodes du score Z et de l'intervalle interquartile. Ces méthodes sont efficaces lorsque les données sous-jacentes suivent une distribution normale (une distribution dans laquelle la plupart des points de données sont plus proches de la moyenne et deviennent moins fréquents à mesure que la distance par rapport à la moyenne augmente). Toutefois, si les données ne sont pas distribuées normalement, ces méthodes peuvent classer à tort les observations normales comme des valeurs aberrantes. \n",
    "\n",
    "En revanche, la méthode Isolation Forest est non paramétrique, ce qui signifie simplement que nous n'avons pas à faire d'hypothèses sur la façon dont les données sous-jacentes sont distribuées.\n",
    "\n",
    "En outre, les méthodes du score Z et de l'intervalle interquartile identifient au niveau de la variable. Si vous avez des raisons de croire que plusieurs variables interagissent entre elles et créent des valeurs aberrantes, ces méthodes ne seront pas en mesure de les détecter. \n",
    "\n",
    "Par exemple, un score SAT de 1350/1600 (90e percentile) ne semble pas être une valeur aberrante en soi. Cependant, si nous introduisons une autre dimension, l'âge, et que nous constatons qu'un enfant de 12 ans a obtenu 1350/1600, cette observation est probablement une valeur aberrante pour un sous-échantillon d'enfants de 12 ans. Contrairement aux méthodes de détection des valeurs aberrantes à une seule variable, Isolation Forest détecte les valeurs aberrantes dans un espace multidimensionnel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342afebb-3b1f-4258-a6c3-90349b94db27",
   "metadata": {},
   "source": [
    "# IQR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e82cc4d-59df-479d-807d-4afa6cd4157b",
   "metadata": {
    "tags": []
   },
   "source": [
    "##  Inter-Quartile Range Method par ligne"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3addf2-02a6-4f55-8656-cfc4c701b92b",
   "metadata": {},
   "source": [
    "La méthode de l'intervalle interquartile, illustrée au mieux par un diagramme en boîte, divise les données en quartiles en définissant trois points :\n",
    "\n",
    "Le quartile 1 (Q1) représente le 25e percentile Le quartile 2 (Q2) représente le 50e percentile Le quartile 3 (Q3) représente le 75e percentile\n",
    "\n",
    "La boîte dans le diagramme en boîte représente l'intervalle IQR qui est défini comme l'intervalle entre Q1 et Q3 ; IQR = Q3 - Q1 et les points de données qui tombent en dessous de Q1 - 1,5*IQR ou au-dessus de Q3 + 1,5*IQR sont définis comme des valeurs aberrantes.\n",
    "\n",
    "Dans le diagramme en boîte, Q1 - 1,5*IQR et Q3 + 1,5*IQR sont représentés par les moustaches et les valeurs aberrantes sont représentées par des points au-dessus ou au-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d83f22-4f02-4ce5-83ba-754918192252",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_quanti:\n",
    "    df_quanti[col]= df_quanti[col].replace([0],np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcefa1d-2b5d-416c-a2ea-f7d703cc3b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = df_quanti[col].quantile(0.25)\n",
    "q3 = df_quanti[col].quantile(0.75)\n",
    "\n",
    "IQR = q3 - q1\n",
    "\n",
    "low_lim = q1 - 1.5 * IQR\n",
    "up_lim = q3 + 1.5 * IQR\n",
    "\n",
    "outlier =[]\n",
    "\n",
    "df_quanti['outlier_IQR']=1\n",
    "for col in df_quanti:\n",
    "    if ((df_quanti[col].max()> up_lim) or (df_quanti[col].min()<low_lim)):\n",
    "        df_quanti['outlier_IQR']=-1\n",
    "        outlier.append(col)\n",
    "print(' outlier in the dataset is', outlier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e303cc9-cf23-4ef3-a359-edad0c6cf1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test  IQR par ligne \n",
    "df_quanti['outlier_IQR']=1\n",
    "\n",
    "for col in df_quanti:\n",
    "    df.loc[df_quanti[col] > up_lim, \"outlier_IQR\"] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4366d91-3503-4b92-940d-a818461c5410",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quanti[df_quanti['outlier_IQR']==-1].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f4f391-9fe8-47a1-b167-78a88ee8fd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quanti.groupby('outlier_IQR').count()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fd153bc7-7ddd-4e24-bf9a-7a6f9f133741",
   "metadata": {},
   "source": [
    "# Find Q1, Q3, IQR and cut off value \n",
    "q25, q75 = np.quantile(df_quanti, 0.25), np.quantile(df_quanti, 0.75)\n",
    "iqr = q75 - q25\n",
    "cutoff = 1.5 * iqr\n",
    "\n",
    "# Define lower and upper boundaries\n",
    "lower, upper = q25 - cutoff, q75 + cutoff\n",
    "\n",
    "# Define new dataset by masking upper and lower boundaries\n",
    "new_glass = df_quanti[(df_quanti > lower) & (df_quanti < upper)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832ae957-d2af-43b7-9add-e22e707cfb61",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Scoring IQR par colonne "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6235c252-c390-4a2b-9def-ad94351aa57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_col_outliers =[]\n",
    "count_outliers = []\n",
    "for col in df_quanti:\n",
    "    columns = 0\n",
    "    if ((df_quanti[col].max()> up_lim) or (df_quanti[col].min()<low_lim)):\n",
    "        count_outliers.append(columns + 1)\n",
    "        list_col_outliers.append(col)\n",
    "print(list_col_outliers)\n",
    "print(sum(count_outliers))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e4b0cf-0667-4ebb-911c-1274f27d55f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "df_outlier = df\n",
    "liste_col_outlier = []\n",
    "for col in df_quanti:\n",
    "    q1 = df_quanti[col].quantile(0.25)\n",
    "    q3 = df_quanti[col].quantile(0.75)\n",
    "    IQR = q3 - q1\n",
    "    low_lim = q1 - 1.5 * IQR\n",
    "    up_lim = q3 + 1.5 * IQR\n",
    "    \n",
    "    conditionlist = [\n",
    "        (df_outlier[col]>= up_lim) | (df_outlier[col]<=low_lim),\n",
    "        (df_outlier[col]< up_lim) & (df_outlier[col]>low_lim)]\n",
    "    choicelist = [-1,0]\n",
    "    df_outlier[col+'_IQR_score'] = np.select(conditionlist, choicelist, default= 0)\n",
    "    if ((df_outlier[col].max()> up_lim) or (df_outlier[col].min()<low_lim)):\n",
    "            liste_col_outlier.append(col)\n",
    "df_outlier = df_outlier.iloc[:,-len(liste_col_outlier):]\n",
    "(df_outlier.sum())*-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac514239-0c91-4f6c-8bbd-6ea6f33dfbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "df['outlier_IQR'] = 0\n",
    "for col in df_quanti:\n",
    "    q1 = df_quanti[col].quantile(0.25)\n",
    "    q3 = df_quanti[col].quantile(0.75)\n",
    "    IQR = q3 - q1\n",
    "    low_lim = q1 - 1.5 * IQR\n",
    "    up_lim = q3 + 1.5 * IQR\n",
    "    conditionlist = [\n",
    "        (df_quanti[col]> up_lim) | (df_quanti[col]<low_lim),\n",
    "        (df_quanti[col]<= up_lim) & (df_quanti[col]>=low_lim) & (df_quanti['outlier_IQR']!=1) ]\n",
    "    choicelist = [1,0]\n",
    "    df['outlier_IQR'] = np.select(conditionlist, choicelist, default= 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24d4d87-c10f-48b0-8465-1ab0a687d0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "# Outlier par colonne\n",
    "df_outlier = df_quanti\n",
    "#Remplacement des valeurs null par les valeurs médian.\n",
    "for col in df_quanti:\n",
    "    df_outlier[col] =df_outlier[col].fillna(df_outlier[col].median())\n",
    "liste_col_outlier = []\n",
    "limit = []\n",
    "for col in df_quanti:\n",
    "    q1 = df_quanti[col].quantile(0.25)\n",
    "    q3 = df_quanti[col].quantile(0.75)\n",
    "    IQR = q3 - q1\n",
    "    low_lim = q1 - 1.5 * IQR\n",
    "    up_lim = q3 + 1.5 * IQR\n",
    "    limit.append(up_lim)\n",
    "    conditionlist = [\n",
    "        (df_outlier[col]> up_lim) | (df_outlier[col]<low_lim),\n",
    "        (df_outlier[col]<= up_lim) & (df_outlier[col]>=low_lim)]\n",
    "    choicelist = [1,0]\n",
    "    df_outlier[col+'_IQR_score'] = np.select(conditionlist, choicelist, default= 0)\n",
    "    if ((df_outlier[col].max()> up_lim) or (df_outlier[col].min()<low_lim)):\n",
    "            liste_col_outlier.append(col)\n",
    "df_outlier = df_outlier.iloc[:,-len(liste_col_outlier):]\n",
    "result = round(((df_outlier.sum())/df_outlier.shape[0])*100,2)\n",
    "result = pd.DataFrame(data=result).reset_index()\n",
    "result.rename(columns={\"index\": \"Column name\", 0: \"% of outlier\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a81adb-cbc7-4412-9af7-a5a6eaab22e9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Z-Score \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76df1efd-8f48-41bb-88cf-f448bc0b623c",
   "metadata": {},
   "source": [
    "La première étape est de détecter les valeurs aberrantes à l'aide de la méthode du score Z.\n",
    "\n",
    "La méthode du score Z est efficace pour traiter les valeurs aberrantes pour les points de données qui suivent une distribution normale.\n",
    "\n",
    "Le score Z indique la distance d'un point de données par rapport à la moyenne en tant que nombre d'écarts types.\n",
    "\n",
    "On suppose que les observations dont le score Z est inférieur à -2,5 ou supérieur à 2,5 (c'est-à-dire 2,5 écarts types par rapport à la moyenne ; 1% de l'échantillon) sont des valeurs aberrantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed484003-4112-46ce-8186-eb25d29c977c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Number of entries, Number of features) Il y a 4626939 entrées et 18 variable\n",
    "print(df_quanti.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a7f094c3-685e-40fd-bade-8ae0e7a9afc5",
   "metadata": {},
   "source": [
    "for col in df_quanti :\n",
    "    sample_z = df_quanti[col].replace([0],np.NaN)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "819850ee-4403-463c-91dc-797223f5e111",
   "metadata": {},
   "source": [
    "zscore = stats.zscore(df['TOTAL_LOYALTY_ATI_AMOUNT'])\n",
    "zscore = pd.DataFrame(data=zscore,columns=['zscore'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ce6509-194a-422b-98e1-3e3beadc3fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_quanti:\n",
    "    df_quanti['outlier_zscore']=0\n",
    "    upper_limit = df_quanti[col].mean() + 3 *  df[col].std()\n",
    "    lower_limit = df_quanti[col].mean() - 3 *  df[col].std()\n",
    "\n",
    "\n",
    "    conditionlist = [\n",
    "        (df_quanti[col] >= upper_limit),\n",
    "        (df_quanti[col] <= lower_limit),\n",
    "        (df_quanti[col] < upper_limit) & (df_quanti[col] > lower_limit) & (df_quanti['outlier_zscore']!=-1)\n",
    "    ]\n",
    "    choicelist = [-1, -1,0]\n",
    "\n",
    "    df['outlier_zscore'] = np.select(conditionlist, choicelist, default= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfd70e6-d6aa-4702-a7c0-fec0d17d85bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quanti.groupby(['outlier_zscore']).count()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "93ffadd2-e0bb-4f1e-9b52-5a91aa121095",
   "metadata": {},
   "source": [
    "# Create a function to report the limits of the Z-Score\n",
    "def print_z_score_limits (df_quanti, TOTAL_ET_AMOUNT):\n",
    "    \"\"\" Print the upper and lower limits of the Z-score \"\"\"\n",
    "    \n",
    "    # Compute the limits\n",
    "    upper_limit = df_quanti[\"TOTAL_ET_AMOUNT\"].mean() + 3 * df_quanti[\"TOTAL_ET_AMOUNT\"].std()\n",
    "    lower_limit = df_quanti[\"TOTAL_ET_AMOUNT\"].mean() - 3 * df_quanti[\"TOTAL_ET_AMOUNT\"].std()\n",
    "    \n",
    "    # Round and return the limits\n",
    "    upper_limit = round(upper_limit, 2)\n",
    "    lower_limit = round(lower_limit, 2)\n",
    "    print_this = \"Variable Name: \" + TOTAL_ET_AMOUNT + \" | Upper limit: \" + str(upper_limit) + \" | Lower limit: \" + str(lower_limit)\n",
    "    return(print_this)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "91b73acc-41ba-4d17-8bad-3226e947c478",
   "metadata": {},
   "source": [
    "# Print the upper and lower limits\n",
    "print_z_score_limits(sample_z_score, \"TOTAL_ET_AMOUNT\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3a76b73e-ac14-47c4-98f5-b93062273cd0",
   "metadata": {},
   "source": [
    "# Filter outliers\n",
    "sample_z = df_quanti[(df_quanti['TOTAL_ET_AMOUNT'] >= -40.92) | (df_quanti['TOTAL_ET_AMOUNT'] <= 62.13)]\n",
    "print(df_quanti.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a0a0dd-d6f0-463e-9854-ddc7a4db848e",
   "metadata": {},
   "source": [
    "Si l'on revient aux histogrammes ci-dessus, on constate que les historammes sont  significativement orientés vers la gauche. Dans ce cas, la méthode du score Z ou d'autres méthodes populaires de détection des valeurs aberrantes, telles que la méthode de l'intervalle interquartile (IQR), n'est d'aucune utilité. Pour résoudre ce problème, j'effectue des transformations logarithmiques sur ces variables pour voir si je peux les décrire avec une distribution normale.\n",
    "\n",
    "L'histogramme montre également que les quatre variables comportent de nombreux zéros (ou de très petites valeurs), ce qui est logique d'un point de vue économique. Par conséquent, je ne chercherai que les valeurs aberrantes du côté droit de la distribution.\n",
    "\n",
    "Tout d'abord, je remplacerai les zéros par des NaN. Cela ne pose pas de problème car les zéros ne seront pas considérés comme des valeurs aberrantes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7c1a54-8cc5-40f2-a4c6-a6f1fd720574",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Isolation Forest - Multidimensional dimension "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156ff637-0abe-473e-b328-9e9d5221f98f",
   "metadata": {},
   "source": [
    "Isolation Forest est un **algorithme d'apprentissage non supervisé** qui appartient à la famille des arbres de décision pour **détecter les anomalies**, proposée pour la première fois par Liu, Ting et Zhou (2008). \n",
    "\n",
    "Contrairement à d'autres méthodes qui tentent d'abord de **comprendre les points normaux** puis identifiaient tout ce qui se trouvait **en dehors de cette région** définie comme une **valeur aberrante ou anormale**.\n",
    "\n",
    "Cette méthode fonctionne différemment. Elle **isole explicitement les anomalies** au lieu d'établir des profils et de construire des points et des régions normaux en attribuant un score à chaque point de données. **Cet algorithme** fonctionne parfaitement avec des **ensembles de données de très grande dimension** et s'est avéré être un moyen très efficace de **détecter les anomalies**. \n",
    "\n",
    "Les anomalies présentent deux caractéristiques. Elles sont éloignées des points normaux et sont peu nombreuses. L'algorithme Isolation Forest exploite ces deux caractéristiques.\n",
    "\n",
    "**Avantages :**\n",
    "\n",
    "- L'Isolation Forest ne suppose pas une distribution normale et est capable de détecter les valeurs aberrantes à un niveau multidimensionnel.\n",
    "- Isolation Forest est efficace en termes de calcul : Par conséquent, il s'adapte bien aux grands ensembles de données.\n",
    "- La forêt d'isolement est plus performante que la forêt aléatoire, en particulier pour les grands ensembles de données.\n",
    "\n",
    "**Inconvénient :**\n",
    "\n",
    "- L'algorithme Isolation Forest exige que nous choisissions le pourcentage d'anomalies dans l'ensemble de données. Nous devons donc avoir au moins une idée de la proportion d'anomalies dans nos données.\n",
    "- Dans le pca on est obligé de réduire les dimensions à 2 pour bien performer, avec l'isolation forest on n'est pas obligé de faire ça car ça marche très bien avec plusieurs dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd73c6fe-516e-47f3-920f-e821f2177acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5446679a-8c50-4a09-b6d3-a301a39e7b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remplacement des valeurs null par les valeurs médian.\n",
    "df_quanti['ITEM_COST'] =df_quanti['ITEM_COST'].fillna(df_quanti['ITEM_COST'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14415c5f-7034-48e8-a005-466beaf0630b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_isf = df_quanti.drop(columns='INVOICE_SHOP_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ad5876-4b75-42e0-b234-0e9c85ffc508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dimensions = 2\n",
    "pca = PCA(n_components=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5398c3-6d28-4b2e-894c-efaa5b0ebe63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conduct the PCA\n",
    "principal_comp = pca.fit_transform(sample_isf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d344dcf-bde2-4730-8898-05de3197ee2d",
   "metadata": {},
   "source": [
    "On va mettre nos résulatts en data frame afin de pouvoir obtenir un score par la suite "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa8186e-e6bf-4b7b-88d7-ec38596492c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to dataframe\n",
    "pca_df = pd.DataFrame(data = principal_comp, columns = ['principal_component_1', 'principal_component_2'])\n",
    "pca_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43dc04a8-e50d-4e48-a12f-2ba22c6a5141",
   "metadata": {},
   "source": [
    "Entrainer le modèle et faire nos prédictions, on utilise un pourcentage de 4% (je ne sais pas trop pk pour l'instant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82db5180-1c9b-4b99-97e0-eacea22facc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "isf = IsolationForest(contamination=0.02)\n",
    "isf.fit(pca_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f2c2ed-95b8-440e-a0c5-62548b2ab5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "predictions = isf.predict(pca_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1ac863-f338-4a60-a007-0145269c9b86",
   "metadata": {},
   "source": [
    "On va ensuite mettre en place des scores grace à nos prédictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31a94a7-b9fc-4ff7-a55c-797df2010ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract scores\n",
    "pca_df[\"iso_forest_scores\"] = isf.decision_function(pca_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aace8c17-834a-44cd-867c-5ce5fc5b02f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract predictions\n",
    "pca_df[\"iso_forest_outliers\"] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954dccce-3738-4ddb-b092-cc04f2fde65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_df.describe()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5b4071fd-4aa2-42e6-b7f6-0b2495f5fdf4",
   "metadata": {},
   "source": [
    "# Replace \"-1\" with \"Yes\" and \"1\" with \"No\"\n",
    "pca_df['iso_forest_outliers'] = pca_df['iso_forest_outliers'].replace([-1, 1], [\"Yes\", \"No\"])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "eb645e64-1c52-47a2-af8e-45dcc04b4b6d",
   "metadata": {},
   "source": [
    "#Afficher les 5 premiers résulats \n",
    "pca_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5a8ae2-705d-49e4-9b1e-100bb9afbc2b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Graphique "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9df27d9-2ddc-4508-b74e-6f6417785a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to plot firms on the 2-dimensional space\n",
    "def plot_firms (dataframe, title, color = None):\n",
    "    \"\"\" Plot firms on the 2-dimensional space \"\"\"\n",
    "    \n",
    "    # Generate a scatter plot\n",
    "    fig = px.scatter(pca_df, x=\"principal_component_1\", y=\"principal_component_2\", title=title, color=color)\n",
    "    \n",
    "    # Layout\n",
    "    fig.update_layout(\n",
    "        font_family='Arial Black',\n",
    "        title=dict(font=dict(size=20, color='red')),\n",
    "        yaxis=dict(tickfont=dict(size=13, color='black'),\n",
    "                   titlefont=dict(size=15, color='black')),\n",
    "        xaxis=dict(tickfont=dict(size=13, color='black'),\n",
    "                   titlefont=dict(size=15, color='black')),\n",
    "        legend=dict(font=dict(size=10, color='black')),\n",
    "        plot_bgcolor='white'\n",
    "    )\n",
    "      \n",
    "    return(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba96ce4-7483-4382-a07f-941a4bcefcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to import renderers to view the plots on GitHub\n",
    "import plotly.io as pio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317b50af-892d-472e-8fee-df860736a3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot [1] All firms\n",
    "plot_firms(pca_df, \"Figure 1: All Firms\").show('png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2ebcd5-a791-4f65-9202-2e9873a09621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [2] Normal Firms vs. Outlier Firms\n",
    "plot_firms(dataframe=pca_df, title=\"Figure 2: Normal Firms vs. Outlier Firms\", color='iso_forest_outliers').show('png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0511b0-4f5a-4dcf-87e7-c5e75652eaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [3] Isolation Forest Scores\n",
    "plot_firms(dataframe=pca_df, title=\"Figure 3: Isolation Forest Scores\", color='iso_forest_scores').show(\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2501fffd-ead0-4d06-92a3-909a39418514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add identifiers and cluster assignments (labels) to the sample\n",
    "pca_df = pd.concat([df_quanti['INVOICE_SHOP_ID'], pca_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ff0b10-68e7-4ff1-92ac-9eb244e68a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the first 5 firms\n",
    "pca_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af3ee46-83b9-46bc-9107-7584dc1d0dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quanti[\"iso_forest_outliers\"] = pca_df[\"iso_forest_outliers\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0725f8d0-4601-461a-972a-0b92cb4dde57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quanti.groupby('iso_forest_outliers').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725f0678-9c36-48bc-831e-480c72aabd0f",
   "metadata": {},
   "source": [
    "# LOF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b60844-b113-474d-9c03-d90a650195b0",
   "metadata": {},
   "source": [
    "Reminder sur les paramètres du LOF : https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.LocalOutlierFactor.html\n",
    "\n",
    " * n_neighbors int, default=20\n",
    "Number of neighbors to use by default for kneighbors queries. If n_neighbors is larger than the number of samples provided, all samples will be used.\n",
    "\n",
    "* metric str or callable, default=’minkowski’\n",
    "Metric to use for distance computation. Default is “minkowski”, which results in the standard Euclidean distance when p = 2. See the documentation of scipy.spatial.distance and the metrics listed in distance_metrics for valid metric values.\n",
    "\n",
    "* contamination ‘auto’ or float, default=’auto’\n",
    "The amount of contamination of the data set, i.e. the proportion of outliers in the data set. When fitting this is used to define the threshold on the scores of the samples.\n",
    "if ‘auto’, the threshold is determined as in the original paper,\n",
    "if a float, the contamination should be in the range (0, 0.5]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a4c214-ce33-4ff8-b18d-e49e7e3576a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyod.models.iforest import IForest\n",
    "from pyod.utils.data import generate_data\n",
    "from pyod.utils.data import evaluate_print\n",
    "from pyod.utils.example import visualize\n",
    "from sklearn.neighbors import LocalOutlierFactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2110be44-7f65-4035-ae8b-3ae5b409013a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model specification\n",
    "model1 = LocalOutlierFactor(n_neighbors = 35 , metric = \"minkowski\", contamination = 0.02)\n",
    "# model fitting\n",
    "y_pred = model1.fit_predict(df_quanti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904bc698-99f1-4a5c-89e1-287d3ec3eb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Nombre d'outliers détectés : \", len(y_pred[y_pred==-1]), ' sur un échantillon de ', df_quanti.shape[0], ' lignes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f098423b-b4af-40c5-9c2b-bb863c43856f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quanti[\"lof_outliers\"] = y_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea7e505-748d-48ef-8a58-8559f96b9b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = df_quanti['lof_outliers']\n",
    "plt.scatter(df_quanti[\"TOTAL_ET_AMOUNT\"], df_quanti[\"TOTAL_ET_AMOUNT_DISCOUNT_EXCLUDED\"], c = colors)\n",
    "\n",
    "# produce a legend with the unique colors from the scatter\n",
    "legend = plt.legend([-1,0], title = \"Legend\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0a43ea34-948e-46cc-bcd3-554374e97101",
   "metadata": {},
   "source": [
    "Test sur un jeu de données "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
